import os
import sys
from pathlib import Path

# Add src to path
current_dir = Path(__file__).resolve().parent
sys.path.append(str(current_dir.parent / "src"))

from ingestion.parsers.parser_html import HTMLParser
from ingestion.loaders import Blob

def test_basic_parsing():
    """æµ‹è¯•åŸºæœ¬HTMLè§£æå’ŒMarkdownè½¬æ¢"""
    print("=== æµ‹è¯•åŸºæœ¬è§£æ ===")
    html_content = """
    <html>
    <head><title>æµ‹è¯•é¡µé¢</title></head>
    <body>
    <h1>ä»‹ç»</h1>
    <p>è¿™æ˜¯ä»‹ç»éƒ¨åˆ†ã€‚</p>
    <h2>ä»£ç éƒ¨åˆ†</h2>
    <pre><code>def hello():
    print("Hello World")</code></pre>
    <h2>è¡¨æ ¼éƒ¨åˆ†</h2>
    <table>
    <tr><th>å§“å</th><th>å¹´é¾„</th></tr>
    <tr><td>å°æ˜</td><td>25</td></tr>
    </table>
    </body>
    </html>
    """.strip()

    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser()
    nodes = parser.parse(blob)

    assert len(nodes) == 3, f"æœŸæœ›3ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(nodes)}"
    assert nodes[0].metadata['section_header'] == 'ä»‹ç»'
    assert 'æµ‹è¯•é¡µé¢' in nodes[0].metadata.get('title', '')
    assert 'def hello():' in nodes[1].text
    assert '|' in nodes[2].text  # è¡¨æ ¼è½¬æ¢ä¸ºMarkdown
    print("âœ“ åŸºæœ¬è§£ææµ‹è¯•é€šè¿‡")

def test_remove_images_and_links():
    """æµ‹è¯•ç§»é™¤å›¾ç‰‡å’Œé“¾æ¥çš„åŠŸèƒ½"""
    print("=== æµ‹è¯•ç§»é™¤å›¾ç‰‡å’Œé“¾æ¥ ===")
    html_content = """
    <html>
    <body>
    <h1>æµ‹è¯•</h1>
    <p>æŸ¥çœ‹è¿™ä¸ª<a href="http://example.com">é“¾æ¥</a>å’Œ<img src="image.jpg" alt="å›¾ç‰‡"></p>
    </body>
    </html>
    """

    # æµ‹è¯•ç§»é™¤é“¾æ¥
    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser(remove_links=True, remove_images=True)
    nodes = parser.parse(blob)

    assert len(nodes) == 1
    text = nodes[0].text
    assert 'http://example.com' not in text, "é“¾æ¥åº”è¯¥è¢«ç§»é™¤"
    assert 'image.jpg' not in text, "å›¾ç‰‡åº”è¯¥è¢«ç§»é™¤"
    print("âœ“ ç§»é™¤å›¾ç‰‡å’Œé“¾æ¥æµ‹è¯•é€šè¿‡")

def test_custom_clean_rules():
    """æµ‹è¯•è‡ªå®šä¹‰æ¸…æ´—è§„åˆ™"""
    print("=== æµ‹è¯•è‡ªå®šä¹‰æ¸…æ´—è§„åˆ™ ===")
    html_content = """
    <html>
    <body>
    <h1>æµ‹è¯•</h1>
    <div class="ad">å¹¿å‘Šå†…å®¹</div>
    <p>æ­£å¸¸å†…å®¹</p>
    <span class="noise">å™ªéŸ³</span>
    </body>
    </html>
    """

    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser(custom_clean_rules=['.ad', '.noise'])
    nodes = parser.parse(blob)

    assert len(nodes) == 1
    text = nodes[0].text
    assert 'å¹¿å‘Šå†…å®¹' not in text, "å¹¿å‘Šåº”è¯¥è¢«ç§»é™¤"
    assert 'å™ªéŸ³' not in text, "å™ªéŸ³åº”è¯¥è¢«ç§»é™¤"
    assert 'æ­£å¸¸å†…å®¹' in text, "æ­£å¸¸å†…å®¹åº”è¯¥ä¿ç•™"
    print("âœ“ è‡ªå®šä¹‰æ¸…æ´—è§„åˆ™æµ‹è¯•é€šè¿‡")

def test_metadata_extraction():
    """æµ‹è¯•å…ƒæ•°æ®æå–"""
    print("=== æµ‹è¯•å…ƒæ•°æ®æå– ===")
    html_content = """
    <html>
    <head>
    <title>é¡µé¢æ ‡é¢˜</title>
    <meta name="description" content="é¡µé¢æè¿°">
    <meta name="keywords" content="å…³é”®è¯1,å…³é”®è¯2">
    <link rel="canonical" href="https://example.com/page">
    </head>
    <body><h1>å†…å®¹</h1></body>
    </html>
    """

    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser()
    nodes = parser.parse(blob)

    assert len(nodes) == 1
    meta = nodes[0].metadata
    assert meta.get('title') == 'é¡µé¢æ ‡é¢˜'
    assert meta.get('description') == 'é¡µé¢æè¿°'
    assert meta.get('keywords') == 'å…³é”®è¯1,å…³é”®è¯2'
    assert meta.get('canonical_url') == 'https://example.com/page'
    print("âœ“ å…ƒæ•°æ®æå–æµ‹è¯•é€šè¿‡")

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
    # ç©ºHTML
    blob = Blob(data=b"", source="empty.html")
    parser = HTMLParser()
    nodes = parser.parse(blob)
    assert len(nodes) == 0, "ç©ºHTMLåº”è¯¥è¿”å›ç©ºèŠ‚ç‚¹åˆ—è¡¨"

    # æ— æ ‡é¢˜çš„HTML
    html_content = "<html><body><p>åªæœ‰æ®µè½</p></body></html>"
    blob = Blob(data=html_content.encode("utf-8"), source="no_title.html")
    nodes = parser.parse(blob)
    assert len(nodes) == 1
    assert nodes[0].metadata['section_header'] == 'Introduction'  # é»˜è®¤æ ‡é¢˜
    print("âœ“ è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")

def test_load_data():
    """æµ‹è¯•load_dataæ–¹æ³•"""
    print("=== æµ‹è¯•load_dataæ–¹æ³• ===")
    # åˆ›å»ºä¸´æ—¶HTMLæ–‡ä»¶
    temp_file = Path("/tmp/test_page.html")
    html_content = "<html><head><title>æ–‡ä»¶æµ‹è¯•</title></head><body><h1>æµ‹è¯•</h1></body></html>"
    temp_file.write_text(html_content, encoding='utf-8')

    try:
        parser = HTMLParser()
        nodes = parser.load_data(str(temp_file))
        assert len(nodes) == 1
        assert nodes[0].metadata.get('title') == 'æ–‡ä»¶æµ‹è¯•'
        print("âœ“ load_dataæ–¹æ³•æµ‹è¯•é€šè¿‡")
    finally:
        temp_file.unlink()

def test_section_path():
    """æµ‹è¯•section_pathå±‚çº§è·¯å¾„"""
    print("=== æµ‹è¯•section_pathå±‚çº§è·¯å¾„ ===")
    html_content = """
    <html>
    <body>
    <h1>ä¸€çº§æ ‡é¢˜</h1>
    <p>ä¸€çº§å†…å®¹</p>
    <h2>äºŒçº§æ ‡é¢˜</h2>
    <p>äºŒçº§å†…å®¹</p>
    <h3>ä¸‰çº§æ ‡é¢˜</h3>
    <p>ä¸‰çº§å†…å®¹</p>
    <h2>å¦ä¸€ä¸ªäºŒçº§æ ‡é¢˜</h2>
    <p>å¦ä¸€ä¸ªäºŒçº§å†…å®¹</p>
    </body>
    </html>
    """

    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser()
    nodes = parser.parse(blob)

    # åº”è¯¥æœ‰4ä¸ªèŠ‚ç‚¹ï¼šä¸€çº§ã€äºŒçº§ã€ä¸‰çº§ã€å¦ä¸€ä¸ªäºŒçº§
    assert len(nodes) == 4
    paths = [node.metadata.get('section_path') for node in nodes]
    expected_paths = [
        "ä¸€çº§æ ‡é¢˜",
        "ä¸€çº§æ ‡é¢˜ > äºŒçº§æ ‡é¢˜",
        "ä¸€çº§æ ‡é¢˜ > äºŒçº§æ ‡é¢˜ > ä¸‰çº§æ ‡é¢˜",
        "ä¸€çº§æ ‡é¢˜ > å¦ä¸€ä¸ªäºŒçº§æ ‡é¢˜"
    ]
    print("âœ“ section_pathå±‚çº§è·¯å¾„æµ‹è¯•é€šè¿‡")

def test_block_protection():
    """æµ‹è¯•å—ä¿æŠ¤ï¼šä»£ç å—ã€æ•°å­¦å…¬å¼å—ã€è¡¨æ ¼å†…çš„å†…å®¹ä¸ä¼šè¢«è¯¯åˆ‡åˆ†"""
    print("=== æµ‹è¯•å—ä¿æŠ¤é€»è¾‘ ===")
    html_content = """
    <html>
    <body>
    <h1>ä¸»è¦å†…å®¹</h1>
    <p>è¿™é‡Œæ˜¯ä¸€äº›å†…å®¹</p>
    <pre><code>
# è¿™ä¸æ˜¯æ ‡é¢˜
def function():
    # è¿™ä¹Ÿä¸æ˜¯æ ‡é¢˜
    return True
    </code></pre>
    <h2>æ•°å­¦éƒ¨åˆ†</h2>
    <p>å…¬å¼ï¼š</p>
    $$
    # è¿™ä¸æ˜¯æ ‡é¢˜
    E = mc^2
    # ä¹Ÿä¸æ˜¯æ ‡é¢˜
    $$
    <h2>è¡¨æ ¼éƒ¨åˆ†</h2>
    <table>
    <tr><th>é¡¹ç›®</th><th>å€¼</th></tr>
    <tr><td># ä¸æ˜¯æ ‡é¢˜</td><td>100</td></tr>
    </table>
    <h1>ç»“å°¾</h1>
    <p>ç»“æŸå†…å®¹</p>
    </body>
    </html>
    """

    blob = Blob(data=html_content.encode("utf-8"), source="test.html")
    parser = HTMLParser()
    nodes = parser.parse(blob)

    # åº”è¯¥æœ‰4ä¸ªèŠ‚ç‚¹ï¼šä¸»è¦å†…å®¹ã€æ•°å­¦éƒ¨åˆ†ã€è¡¨æ ¼éƒ¨åˆ†ã€ç»“å°¾
    assert len(nodes) == 4
    headers = [node.metadata.get('section_header') for node in nodes]
    expected_headers = ["ä¸»è¦å†…å®¹", "æ•°å­¦éƒ¨åˆ†", "è¡¨æ ¼éƒ¨åˆ†", "ç»“å°¾"]
    assert headers == expected_headers, f"æœŸæœ›æ ‡é¢˜: {expected_headers}, å®é™…: {headers}"
    
    # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«äº†ä»£ç å—å’Œæ•°å­¦å…¬å¼å—
    content_main = nodes[0].text
    content_math = nodes[1].text
    assert "def function():" in content_main, "ä»£ç å—åº”è¯¥åŒ…å«åœ¨ä¸»è¦å†…å®¹ä¸­"
    assert "E = mc^2" in content_math, "æ•°å­¦å…¬å¼åº”è¯¥åŒ…å«åœ¨æ•°å­¦éƒ¨åˆ†ä¸­"
    
    print("âœ“ å—ä¿æŠ¤é€»è¾‘æµ‹è¯•é€šè¿‡")

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹HTMLParseråŠŸèƒ½æµ‹è¯•...\n")
    try:
        test_basic_parsing()
        test_remove_images_and_links()
        test_custom_clean_rules()
        test_metadata_extraction()
        test_section_path()
        test_block_protection()
        test_edge_cases()
        test_load_data()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼HTMLParseråŠŸèƒ½æ­£ç¡®å®ç°ã€‚")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    run_all_tests()